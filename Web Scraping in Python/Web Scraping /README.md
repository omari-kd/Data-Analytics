# Web Scraping Wikipedia with Requests, BeautifulSoup and Pandas

This project demonstrates how to scrape data from Wikipedia using Python libraries: `requests`, `BeautifulSoup` and `pandas`. The scraped data is then saved to a CSV file for further analysis or visualization.

---

## Objective

To extract data from the [Wikipedia page on highest-grossing films](https://en.wikipedia.org/wiki/List_of_highest-grossing_films) and save it as a structured CSV file.

---

## Tools & Libraries

- [`requests`](https://docs.python-requests.org/): To fetch the HTML content of the webpage.
- [`BeautifulSoup`](https://www.crummy.com/software/BeautifulSoup/): To parse and navigate the HTML.
- [`pandas`](https://pandas.pydata.org/): To structure and export data to CSV.

---

## How to Run

### 1. Clone the repository

```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name

```
